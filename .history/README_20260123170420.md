# Qwen3-TTS Voice Clone Studio

A Gradio-based web UI for voice cloning and voice design using Qwen3-TTS models.

![Voice Clone Studio](https://img.shields.io/badge/Qwen3--TTS-Voice%20Clone%20Studio-blue)

## Features

### üé§ Voice Clone
Clone voices from your own audio samples. Just provide a 3-10 second reference audio with its transcript, and generate new speech in that voice.

- **Voice prompt caching** - First generation processes the sample, subsequent ones are instant
- **Seed control** - Reproducible results with saved seeds
- **Metadata tracking** - Each output saves generation info (sample, seed, text)

### üé® Voice Design
Create voices from natural language descriptions - no audio needed!

- Describe age, gender, emotion, accent, speaking style
- Generate unique voices matching your description

### üîÑ Design ‚Üí Clone
Best of both worlds: design a voice with instructions, then clone it for full control.

1. Design a reference voice with natural language
2. Use that designed voice to generate any new content
3. Gives you style control that pure cloning doesn't offer

### üéõÔ∏è Prep Samples
Full audio preparation workspace:

- **Trim** - Use waveform selection to cut audio
- **Normalize** - Balance audio levels
- **Convert to Mono** - Ensure single-channel audio
- **Transcribe** - Whisper-powered automatic transcription
- **Save as Sample** - One-click sample creation

## Installation

### Prerequisites

- Python 3.10+
- CUDA-compatible GPU (recommended: 8GB+ VRAM)
- [Flash Attention 2](https://github.com/Dao-AILab/flash-attention) (optional but recommended)

### Setup

1. Clone the repository:
```bash
git clone https://github.com/yourusername/Qwen3-TTS-Voice-Clone-Studio.git
cd Qwen3-TTS-Voice-Clone-Studio
```

2. Create a virtual environment:
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. (Optional) Install Flash Attention 2 for better performance:
```bash
pip install flash-attn --no-build-isolation
```

## Usage

### Launch the UI

```bash
python voice_clone_ui.py
```

Or use the batch file (Windows):
```bash
__Launch_UI.bat
```

The UI will open at `http://127.0.0.1:7860`

### Prepare Voice Samples

1. Go to the **Prep Samples** tab
2. Upload or record audio (3-10 seconds of clear speech)
3. Trim and normalize as needed
4. Transcribe or manually enter the text
5. Save as a sample with a name

### Clone a Voice

1. Go to the **Voice Clone** tab
2. Select your sample from the dropdown
3. Enter the text you want to speak
4. Click Generate

### Design a Voice

1. Go to the **Voice Design** tab
2. Enter the text to speak
3. Describe the voice (e.g., "Young female, warm and friendly, slight British accent")
4. Click Generate

## Project Structure

```
Qwen3-TTS-Voice-Clone-Studio/
‚îú‚îÄ‚îÄ voice_clone_ui.py      # Main Gradio application
‚îú‚îÄ‚îÄ voice_clone.py         # CLI version (optional)
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ __Launch_UI.bat        # Windows launcher
‚îú‚îÄ‚îÄ samples/               # Voice samples (.wav + .txt pairs)
‚îÇ   ‚îî‚îÄ‚îÄ example.wav
‚îÇ   ‚îî‚îÄ‚îÄ example.txt
‚îú‚îÄ‚îÄ output/                # Generated audio outputs
‚îî‚îÄ‚îÄ Qwen/                  # Model weights (auto-downloaded)
```

## Models Used

- **Qwen3-TTS-12Hz-1.7B-Base** - Voice cloning
- **Qwen3-TTS-12Hz-1.7B-VoiceDesign** - Voice design from descriptions
- **Whisper Medium** - Audio transcription

Models are automatically downloaded on first use.

## Tips

- **Reference Audio**: Use clear, noise-free recordings (3-10 seconds)
- **Transcripts**: Should exactly match what's spoken in the audio
- **Caching**: Voice prompts are cached - first generation is slow, subsequent ones are fast
- **Seeds**: Use the same seed to reproduce identical outputs

## License

This project uses the Qwen3-TTS models which are licensed under Apache 2.0.

## Acknowledgments

- [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS) by Alibaba
- [Gradio](https://gradio.app/) for the web UI framework
- [OpenAI Whisper](https://github.com/openai/whisper) for transcription
